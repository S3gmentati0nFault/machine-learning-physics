import numpy as np
import matplotlib.pyplot as plt
from collections import namedtuple

CONSTANTS = namedtuple('CONSTANTS', ['STARTING_KAPPA_VALUE', 'ENDING_KAPPA_VALUE', 'NUMBER_OF_STEPS', 'STEP_SIZE', 'DEBUGGING'])

constants = CONSTANTS(0.24, 0.3, 24, (0.3 - 0.24) / 24, False)


# Lattice diagrams

training_set = np.load('lattice_train.npy')
test_set = np.load('lattice_test.npy')
colors = ["blue", "dodgerblue", "deepskyblue", "darkturquoise", "aqua"]

i = 0
while i <= 4:    
    current_color = colors[i]

    if i == 0:
        lattice_sites = test_set[0]
    else:
        lattice_sites = test_set[(i * 6) - 1];

    if constants.DEBUGGING:
        print(i * 6)
    
    for lattice_site in lattice_sites:
        feature1 = lattice_site[:, 0]
        feature2 = lattice_site[:, 1]
        plt.scatter(feature1, feature2, marker=".", color=current_color)
        plt.title('2D projection of the sites for k = ' + str((constants.STEP_SIZE * i * 6) + constants.STARTING_KAPPA_VALUE))
        plt.xlabel('X axis')
        plt.ylabel('Y axis')
    
    plt.show()
    i += 1


# MARKDOWN EXPLANATION OF THE ABOVE


# Design the Convolutional neural network for the problem
import tensorflow as tf
from tensorflow.keras import datasets, models, layers

training_set_X = np.append(training_set[0], training_set[1], axis=0)
training_set_Y = np.append(np.full(1000, 0.24), np.full(1000, 0.3))

print(np.shape(test_set))
test_set_X = test_set[0]
test_set_Y = np.full(100, constants.STARTING_KAPPA_VALUE)
i = 1
while i < constants.NUMBER_OF_STEPS:
    test_set_X = np.append(test_set_X, test_set[i, :], axis=0)
    test_set_Y = np.append(test_set_Y, np.full(100, constants.STARTING_KAPPA_VALUE + (i * constants.STEP_SIZE)))
    i += 1
print(np.shape(test_set_X))

print(np.shape(test_set_Y))

# Setup for the CNN
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(16, 16, 1)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(constants.NUMBER_OF_STEPS, activation='softmax'))
model.add(layers.Dense(10))
model.summary()


model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model.fit(training_set_X, training_set_Y, epochs=10, validation_data=(test_set_X, test_set_Y))


plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_accuracy = model.evaluate(test_set_X, test_set_Y, verbose = 2)
print(test_accuracy)


# 


# Train the network using BCE loss


# Evaluate the network on the test set
